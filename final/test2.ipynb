{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ghanb\\anaconda3\\envs\\cheminfo\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "from train import *\n",
    "from model import *\n",
    "from features import *\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21255, 147, 6)\n",
      "dict_keys(['gene_names', 'mols', 'cell_types'])\n",
      "['T cells CD4+', 'T regulatory cells', 'T cells CD8+', 'NK cells', 'B cells', 'Myeloid cells']\n",
      "(18211, 146, 4)\n",
      "(18211, 17, 2)\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{data_dir}/adata.npy\", \"rb\") as f:\n",
    "    data = np.load(f)[0].squeeze()\n",
    "    print(data.shape)\n",
    "with open(f\"{data_dir}/adata.npy.meta.pickle\", \"rb\") as f:\n",
    "    meta = pkl.load(f)\n",
    "    print(meta.keys())\n",
    "    print(meta[\"cell_types\"])\n",
    "\n",
    "with open(f\"{data_dir}/de_train.npy\", \"rb\") as f:\n",
    "    de_train = np.load(f)\n",
    "    print(de_train.shape)\n",
    "with open(f\"{data_dir}/de_val.npy\", \"rb\") as f:\n",
    "    de_val = np.load(f)\n",
    "    print(de_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtypes = meta[\"mols\"]\n",
    "mol_transforms = {\n",
    "    \"morgan2_fp\": TransformList([Sm2Smiles(\"../config/sm_smiles.csv\", mode=\"path\"), Smiles2Mol(), Mol2Morgan(2048, 2)]),\n",
    "    \"morgan3_fp\": TransformList([Sm2Smiles(\"../config/sm_smiles.csv\", mode=\"path\"), Smiles2Mol(), Mol2Morgan(2048, 3)]),\n",
    "    \"one_hot\": TransformList([Type2OneHot(mtypes)])\n",
    "}\n",
    "\n",
    "ctypes = meta[\"cell_types\"]\n",
    "\n",
    "gene_num = len(meta[\"gene_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExprAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim, bottle_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(x_dim, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, bottle_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottle_dim, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, x_dim)\n",
    "        )\n",
    "\n",
    "        self.float()\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        x = x.to(device)\n",
    "        self.to(device)\n",
    "        # u = torch.rand(1)\n",
    "        # drop = nn.Dropout(float(u))\n",
    "        # x = drop(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class MolAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim, bottle_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(x_dim, 500),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(500, bottle_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottle_dim, 500),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(500, x_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.float()\n",
    "    \n",
    "    def forward(self, x, device):\n",
    "        x = x.to(device)\n",
    "        self.to(device)\n",
    "        u = float(torch.rand(1)) * 0.5 + 0.3\n",
    "        drop = nn.Dropout(u)\n",
    "        x = drop(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#### LOADERS, DATA ####\n",
    "dataset_train = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_val = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_train.configure(sm_out_feature=\"morgan2_fp\", mode=\"train\")\n",
    "dataset_val.configure(sm_out_feature=\"morgan2_fp\", mode=\"validation\")\n",
    "train_dataloader = DataLoader(dataset_train, 32)\n",
    "val_dataloader = DataLoader(dataset_val, 32)\n",
    "\n",
    "#### MODEL ####\n",
    "mol_ae = MolAutoEncoder(x_dim=2048,\n",
    "                        bottle_dim=30)\n",
    "\n",
    "#### TRAINING ####\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction=\"mean\") # loss_mrrmse\n",
    "optimizer = Adam(mol_ae.parameters(), lr=lr, weight_decay=5e-3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=7)\n",
    "\n",
    "#### BATCH PROCESSING ####\n",
    "def process_batch(batch):\n",
    "\n",
    "    x_batch, (y_batch, mask_batch) = batch\n",
    "    y_batch = y_batch.to(device)\n",
    "    mask_batch = mask_batch.to(device)\n",
    "    x_batch[1] = x_batch[1].to(device)\n",
    "    x_pred = mol_ae(x_batch[1].float(), device) # TODO: Send to device the x in model?\n",
    "\n",
    "    loss = loss_fn(x_pred, x_batch[1])\n",
    "    return loss\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/mol_ae_rand_final/bottle30_reg5e3\")\n",
    "\n",
    "#### RUN ####\n",
    "train_many_epochs(mol_ae, train_dataloader, val_dataloader, epochs, \n",
    "                  process_batch, optimizer, scheduler, writer=writer, device=device)\n",
    "\n",
    "torch.save(mol_ae, \"mol_ae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21255,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:04<07:15,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:07<05:32,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:09<04:57,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:12<04:39,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:15<04:29,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:17<04:21,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:20<04:16,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:23<04:11,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:25<04:07,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:28<04:05,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:31<04:01,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:34<03:58,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:36<03:55,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n",
      "tensor([], device='cuda:0', size=(0, 16049), dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:38<04:18,  2.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghanb\\Desktop\\Main\\Projects\\Kaggle_SCP\\final\\test2.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m\"\u001b[39m\u001b[39m./runs/expr_ae_rand_newnew/bottle100_reg1e4_almosttfinal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m#### RUN ####\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m train_many_epochs(cell_ae, train_dataloader, val_dataloader, epochs, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                   process_batch, optimizer, scheduler, writer\u001b[39m=\u001b[39;49mwriter, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m torch\u001b[39m.\u001b[39msave(cell_ae, \u001b[39m\"\u001b[39m\u001b[39mcell_ae.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ghanb\\Desktop\\Main\\Projects\\Kaggle_SCP\\final\\train.py:100\u001b[0m, in \u001b[0;36mtrain_many_epochs\u001b[1;34m(model, train_loader, val_loader, epochs, process_batch, optimizer, scheduler, metrics, writer, device)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_many_epochs\u001b[39m(model, train_loader, val_loader, epochs,\n\u001b[0;32m     93\u001b[0m                       process_batch, optimizer, scheduler\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \n\u001b[0;32m     94\u001b[0m                       metrics\u001b[39m=\u001b[39m[], writer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     96\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m         \u001b[39m# Train model for one epoch and calculate metrics for the \u001b[39;00m\n\u001b[0;32m     99\u001b[0m         \u001b[39m# resulting model...\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m         train_b_losses \u001b[39m=\u001b[39m train_one_epoch(model, train_loader, process_batch, \n\u001b[0;32m    101\u001b[0m                                          optimizer, device)\n\u001b[0;32m    102\u001b[0m         train_b_metrics \u001b[39m=\u001b[39m infer_model(model, train_loader, process_batch, \n\u001b[0;32m    103\u001b[0m                                       metrics, device)\n\u001b[0;32m    104\u001b[0m         val_b_losses, val_b_metrics \u001b[39m=\u001b[39m infer_model(model, val_loader, process_batch, \n\u001b[0;32m    105\u001b[0m                                     metrics, device, calculate_loss\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ghanb\\Desktop\\Main\\Projects\\Kaggle_SCP\\final\\train.py:34\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, process_batch, optimizer, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m---> 34\u001b[0m     loss \u001b[39m=\u001b[39m process_batch(batch)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# x_batch, (y_batch, mask_batch) = batch\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m# y_batch = y_batch.to(device)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39m# mask_batch = mask_batch.to(device)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[39m# y_pred = model(*x_batch, device) # TODO: Send to device the x in model?\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m     \u001b[39m# loss = loss_fn(y_pred, y_batch, mask_batch)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;32mc:\\Users\\ghanb\\Desktop\\Main\\Projects\\Kaggle_SCP\\final\\test2.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_batch\u001b[39m(batch):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x_batch, (y_batch, mask_batch) \u001b[39m=\u001b[39m batch\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     mask_batch \u001b[39m=\u001b[39m mask_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ghanb/Desktop/Main/Projects/Kaggle_SCP/final/test2.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x_batch[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m x_batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### LOADERS, DATA ####\n",
    "dataset_train = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_val = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_train.configure(sm_out_feature=\"morgan2_fp\", mode=\"train\")\n",
    "dataset_val.configure(sm_out_feature=\"morgan2_fp\", mode=\"validation\")\n",
    "train_dataloader = DataLoader(dataset_train, 16)\n",
    "val_dataloader = DataLoader(dataset_val, 16)\n",
    "\n",
    "#### MODEL ####\n",
    "cell_ae = ExprAutoEncoder(x_dim=len(dataset_train.gene_names_control),\n",
    "                          bottle_dim=100)\n",
    "\n",
    "#### TRAINING ####\n",
    "lr = 0.005\n",
    "epochs = 100\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loss_fn = loss_mrrmse\n",
    "optimizer = Adam(cell_ae.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=7)\n",
    "\n",
    "#### BATCH PROCESSING ####\n",
    "gi = dataset_train.gene_idx\n",
    "print(gi.shape)\n",
    "def process_batch(batch):\n",
    "\n",
    "    x_batch, (y_batch, mask_batch) = batch\n",
    "    y_batch = y_batch.to(device)\n",
    "    mask_batch = mask_batch.to(device)\n",
    "    x_batch[0] = x_batch[0].to(device)\n",
    "\n",
    "    u = float(torch.rand(1))\n",
    "    # if u > 0.9:\n",
    "    #     x_pred = cell_ae(x_batch[0].float(), device) # TODO: Send to device the x in model?\n",
    "    #     loss = loss_fn(x_pred, x_batch[0])\n",
    "    #     print(loss)\n",
    "    #     return loss\n",
    "    # else: \n",
    "    y_pred = cell_ae(y_batch.float(), device)\n",
    "    mnotnan = mask_batch.sum(1) > 0\n",
    "    loss = loss_fn(y_pred[mnotnan], y_batch[mnotnan], mask_batch[mnotnan])\n",
    "    if torch.isnan(loss):\n",
    "        print(mask_batch[mnotnan])\n",
    "    return loss\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/expr_ae_rand_newnew/bottle100_reg1e4_almosttfinal\")\n",
    "\n",
    "#### RUN ####\n",
    "train_many_epochs(cell_ae, train_dataloader, val_dataloader, epochs, \n",
    "                  process_batch, optimizer, scheduler, writer=writer, device=device)\n",
    "torch.save(cell_ae, \"cell_ae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:51<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#### LOADERS, DATA ####\n",
    "dataset_train = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_val = C2PDataset(data, meta, sm_transforms=mol_transforms)\n",
    "dataset_train.configure(sm_out_feature=\"morgan2_fp\", mode=\"train\")\n",
    "dataset_val.configure(sm_out_feature=\"morgan2_fp\", mode=\"validation\")\n",
    "dataset_train_pval = CP2DEDataset(de_train, dataset_train)\n",
    "dataset_val_pval = CP2DEDataset(de_val, dataset_val)\n",
    "train_dataloader = DataLoader(dataset_train_pval, 32)\n",
    "val_dataloader = DataLoader(dataset_val_pval, 32)\n",
    "\n",
    "#### MODEL ####\n",
    "pval_model = nn.Sequential(\n",
    "    nn.Linear(45, 250),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(250, 250),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(250, 500),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(500, 2500),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(2500, 18211)\n",
    ")\n",
    "pval_model.to(\"cuda:0\")\n",
    "\n",
    "#### TRAINING ####\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loss_fn = loss_mrrmse\n",
    "optimizer = Adam(pval_model.parameters(), lr=lr, weight_decay=5e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=7)\n",
    "\n",
    "#### BATCH PROCESSING ####\n",
    "def process_batch(batch):\n",
    "\n",
    "    (x_batch, (y_batch, mask_batch)), final_y = batch\n",
    "    y_batch = y_batch.to(device)\n",
    "    final_y = final_y.to(device)\n",
    "    mask_batch = mask_batch.to(device)\n",
    "    x_batch[0], x_batch[1] = x_batch[0].to(device), x_batch[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        enc_cell = cell_ae.encoder(x_batch[0].float())\n",
    "        enc_mol = mol_ae.encoder(x_batch[1].float())\n",
    "    y_pred = pval_model(torch.concat([enc_cell, enc_mol], dim=1)) # TODO: Send to device the x in model?\n",
    "\n",
    "    loss = loss_fn(y_pred, final_y)\n",
    "    return loss\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/pval_model_final/cell15_mol30_reg5e3_nplus_try4\")\n",
    "\n",
    "#### RUN ####\n",
    "train_many_epochs(pval_model, train_dataloader, val_dataloader, epochs, \n",
    "                  process_batch, optimizer, scheduler, writer=writer, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
