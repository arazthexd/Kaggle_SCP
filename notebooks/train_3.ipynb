{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import *\n",
    "from features import *\n",
    "from train import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_df = pd.read_parquet(\"../data/de_train.parquet\")\n",
    "\n",
    "train_index, val_index = stratified_split(de_df[\"cell_type\"], 0.2, 45)\n",
    "de_df_dataset_train = DataFrameDataset(de_df.iloc[train_index], mode=\"df\")\n",
    "de_df_dataset_val = DataFrameDataset(de_df.iloc[val_index], mode=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtypes = list(set(de_df[\"sm_name\"].to_list()))\n",
    "mol_transforms = {\n",
    "    \"morgan2_fp\": TransformList([Sm2Smiles(\"../config/sm_smiles.csv\", mode=\"path\"), Smiles2Mol(), Mol2Morgan(2048, 2)]),\n",
    "    \"morgan3_fp\": TransformList([Sm2Smiles(\"../config/sm_smiles.csv\", mode=\"path\"), Smiles2Mol(), Mol2Morgan(2048, 3)]),\n",
    "    \"one_hot\": TransformList([Type2OneHot(mtypes)])\n",
    "}\n",
    "\n",
    "ctypes = list(set(de_df[\"cell_type\"].to_list()))\n",
    "\n",
    "file_names = [\"../data/temp/\"+name.replace(\" \", \"_\").replace(\"+\", \"\")+\"_control_mean.csv\"\n",
    "              for name in ctypes]\n",
    "gene_num = len(pd.read_csv(file_names[0]))\n",
    "\n",
    "cell_transforms = {\n",
    "    \"one_hot\": TransformList([Type2OneHot(ctypes)]),\n",
    "    \"gene_exp\": TransformList([CType2CSVEncoding(ctypes, file_names)])\n",
    "    # \"gene_exp\": TransformList([CType2CSVEncoding(ctypes, file_names), NormCount2CPM()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_dataset_train = DEDataset(de_df_dataset_train, mol_transforms, cell_transforms)\n",
    "de_dataset_val = DEDataset(de_df_dataset_val, mol_transforms, cell_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL ####\n",
    "cell_ae = VecAutoEncoder([gene_num, 500, 250, 100])\n",
    "\n",
    "#### LOADERS, DATA ####\n",
    "train_dataloader_ = DataLoader(de_dataset_train, 128)\n",
    "val_dataloader_ = DataLoader(de_dataset_val, 128)\n",
    "de_dataset_train.configure(cell_out_feature=\"gene_exp\", ae_mode=\"cell\")\n",
    "de_dataset_val.configure(cell_out_feature=\"gene_exp\", ae_mode=\"cell\")\n",
    "\n",
    "#### CONFIG ####\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(cell_ae.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=7)\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/cell_ae/4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 30.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_many_epochs(cell_ae, train_dataloader_, val_dataloader_, epochs, \n",
    "                  loss_fn, optimizer, scheduler, writer=writer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL ####\n",
    "mol_ae = VecAutoEncoder([2048, 500, 250, 100])\n",
    "\n",
    "#### LOADERS, DATA ####\n",
    "train_dataloader_ = DataLoader(de_dataset_train, 128)\n",
    "val_dataloader_ = DataLoader(de_dataset_val, 128)\n",
    "de_dataset_train.configure(sm_out_feature=\"morgan2_fp\", ae_mode=\"sm\")\n",
    "de_dataset_val.configure(sm_out_feature=\"morgan2_fp\", ae_mode=\"sm\")\n",
    "\n",
    "#### CONFIG ####\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(mol_ae.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=7)\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/mol_ae/2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 23.98it/s]\n"
     ]
    }
   ],
   "source": [
    "train_many_epochs(mol_ae, train_dataloader_, val_dataloader_, epochs, \n",
    "                  loss_fn, optimizer, scheduler, writer=writer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMolEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, num_h, out_size, skip=3):\n",
    "        super(MyMolEncoder, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_size, 100)\n",
    "        self.act_1 = nn.LeakyReLU()\n",
    "        self.h_layers = nn.ModuleList()\n",
    "        for i in range(num_h):\n",
    "            self.h_layers.append(nn.Sequential(\n",
    "                nn.Linear(100, 100),\n",
    "                nn.BatchNorm1d(100),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ))\n",
    "        self.last_layer = nn.Linear(100, out_size)\n",
    "        self.norm = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.skip = skip\n",
    "        self.num_h = num_h\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer_1(x)\n",
    "        x = self.act_1(x)\n",
    "        for i, layer in enumerate(self.h_layers):\n",
    "            x = layer(x)\n",
    "            if i % self.skip == 0:\n",
    "                x_skip = x\n",
    "            if i % self.skip == self.skip - 1:\n",
    "                x = x + x_skip\n",
    "\n",
    "        return x\n",
    "\n",
    "class MyEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, num_h, out_size, skip=3, h_size=100, ini_batch_norm=False):\n",
    "        super(MyEncoder, self).__init__()\n",
    "\n",
    "        self.if_ini_batch = ini_batch_norm\n",
    "        self.ini_batch_norm = nn.BatchNorm1d(in_size)\n",
    "        \n",
    "\n",
    "        self.layer_1 = nn.Linear(in_size, h_size)\n",
    "        self.act_1 = nn.LeakyReLU()\n",
    "        self.h_layers = nn.ModuleList()\n",
    "        for i in range(num_h):\n",
    "            self.h_layers.append(nn.Sequential(\n",
    "                nn.Linear(h_size, h_size),\n",
    "                nn.BatchNorm1d(h_size),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ))\n",
    "        self.last_layer = nn.Linear(h_size, out_size)\n",
    "\n",
    "        self.skip = skip\n",
    "        self.num_h = num_h\n",
    "\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.if_ini_batch == True:\n",
    "            x = self.ini_batch_norm(x)\n",
    "            \n",
    "        x = self.layer_1(x)\n",
    "        x = self.act_1(x)\n",
    "        for i, layer in enumerate(self.h_layers):\n",
    "            x = layer(x)\n",
    "            if i % self.skip == 0:\n",
    "                x_skip = x\n",
    "            if i % self.skip == self.skip - 1:\n",
    "                x = x + x_skip\n",
    "        x = self.last_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "#### LOADERS, DATA ####\n",
    "de_dataset_train.configure(sm_out_feature=\"morgan3_fp\",\n",
    "                           cell_out_feature=\"gene_exp\", ae_mode=False)\n",
    "de_dataset_val.configure(sm_out_feature=\"morgan3_fp\",\n",
    "                           cell_out_feature=\"gene_exp\", ae_mode=False)\n",
    "train_dataloader = DataLoader(de_dataset_train, 64)\n",
    "val_dataloader = DataLoader(de_dataset_val, 64)\n",
    "\n",
    "#### MODEL ####\n",
    "mol_enc = MyEncoder(2048, 6, 300, 3, 450)\n",
    "# mol_enc = VecAEEncoder(mol_ae, grads=True, device=device)\n",
    "cell_enc = MyEncoder(gene_num, 6, 300, 3, 450)\n",
    "# cell_enc = VecAEEncoder(cell_ae, grads=True, device=device)\n",
    "regressor = MyEncoder(600, 6, len(de_df.columns)-5, 3, 800)\n",
    "\n",
    "model = CombinerModel(\n",
    "        mol_encoder=mol_enc,\n",
    "        cell_encoder=cell_enc,\n",
    "        regressor=regressor)\n",
    "torch.save(model.state_dict(), \"temp/ini_model.pkl\")\n",
    "\n",
    "#### CONFIG ####\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "loss_fn = loss_fn\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=10)\n",
    "\n",
    "#### TENSORBOARD ####\n",
    "writer = SummaryWriter(\"./runs/test/18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:09<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "train_many_epochs(model, train_dataloader, val_dataloader, epochs, \n",
    "                  loss_fn, optimizer, scheduler, writer=writer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: morgan2_fp, cell feat: one_hot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:00<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: morgan2_fp, cell feat: gene_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:00<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: morgan3_fp, cell feat: one_hot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:01<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: morgan3_fp, cell feat: gene_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:01<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: one_hot, cell feat: one_hot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:00<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol feat: one_hot, cell feat: gene_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:59<00:00,  8.41it/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "sm_feats = de_dataset_train.sm_feats.keys()\n",
    "cell_feats = de_dataset_train.cell_feats.keys()\n",
    "\n",
    "for sm_feat in sm_feats:\n",
    "    for cell_feat in cell_feats:\n",
    "        \n",
    "        sm_input_size = len(mtypes)\n",
    "        cell_input_size = len(ctypes)\n",
    "        \n",
    "        if \"fp\" in sm_feat:\n",
    "            sm_input_size = 2048\n",
    "        if cell_feat == \"gene_exp\":\n",
    "            cell_input_size = gene_num\n",
    "\n",
    "        #### LOADERS, DATA ####\n",
    "        de_dataset_train.configure(sm_out_feature=sm_feat,\n",
    "                                cell_out_feature=cell_feat, ae_mode=False)\n",
    "        de_dataset_val.configure(sm_out_feature=sm_feat,\n",
    "                                cell_out_feature=cell_feat, ae_mode=False)\n",
    "        train_dataloader = DataLoader(de_dataset_train, 256)\n",
    "        val_dataloader = DataLoader(de_dataset_val, 256)\n",
    "\n",
    "        #### MODEL ####\n",
    "        mol_enc = nn.Sequential(\n",
    "            nn.Linear(sm_input_size, 150),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(150, 300)\n",
    "        ).float()\n",
    "        if cell_feat == \"gene_exp\":\n",
    "            cell_enc = nn.Sequential(\n",
    "                # VecAEEncoder(cell_ae, grads=False, device=device)\n",
    "                nn.BatchNorm1d(cell_input_size),\n",
    "                nn.Linear(cell_input_size, 150),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(150, 300)\n",
    "            ).float()\n",
    "        else:\n",
    "            cell_enc = nn.Sequential(\n",
    "                # VecAEEncoder(cell_ae, grads=False, device=device)\n",
    "                # nn.BatchNorm1d(cell_input_size),\n",
    "                nn.Linear(cell_input_size, 150),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(150, 300)\n",
    "            ).float()\n",
    "        regressor = nn.Sequential(\n",
    "            nn.Linear(600, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1000, len(de_df.columns)-5)\n",
    "        ).float()\n",
    "\n",
    "        model = CombinerModel(\n",
    "                mol_encoder=mol_enc,\n",
    "                cell_encoder=cell_enc,\n",
    "                regressor=regressor)\n",
    "        torch.save(model.state_dict(), \"temp/ini_model.pkl\")\n",
    "\n",
    "        #### CONFIG ####\n",
    "        lr = 0.01\n",
    "        epochs = 500\n",
    "\n",
    "        loss_fn = loss_fn\n",
    "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.85, patience=7)\n",
    "\n",
    "        #### TENSORBOARD ####\n",
    "        writer = SummaryWriter(f\"./runs/compare_xxxlarge/{sm_feat}_{cell_feat}\")\n",
    "\n",
    "        #### TRAIN ####\n",
    "        print(f\"mol feat: {sm_feat}, cell feat: {cell_feat}\")\n",
    "        train_many_epochs(model, train_dataloader, val_dataloader, epochs, \n",
    "                  loss_fn, optimizer, scheduler, writer=writer, device=device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
